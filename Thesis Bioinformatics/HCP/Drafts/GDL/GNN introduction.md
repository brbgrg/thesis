GNNs are among the hottest topics nowadays thanks to their benefits in learning on a wide range of graphs, both directed and undirected. GNNs have emerged as subfield of the broader field of “geometric deep learning” on nonEuclidean data. Broadly, GNNs can be categorized into three big classes [46], either by aggregating the features of neighborhood nodes with a learnable filter, as in Graph Convolutional Network (GCN) [51] or based on the self-attention strategy which identifies the most important neighbors to be aggregated, as in Graph Attention Network (GAT) [52] or even based on a message-passing mechanism where features of both node in consideration and its neighboring nodes are combined to learn the local graph representation, as in [53]. While it presents an attractive opportunity for network neuroscience, only a few GNN architectures have so far been applied to the brain connectome and the most used GNN model is GCN [51]. Therefore, we choose to cover it in detail in this section and for a more in-depth review of other variants of GNNs, we kindly refer the reader to [42]–[44], [46].
(Bessadok 2015)


Recently, functional brain networks have been employed for classifying neurological disorders, such as autism spectrum disorders (ASDs). Graph convolutional networks (GCNs) have been shown to be successful in modeling applications with graph structures.
(Cao 2022)


